{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('bfv_tensor', <function bfv_tensor at 0x7f04f92f0790>), ('bfv_tensor_from', <function bfv_tensor_from at 0x7f04f92f0820>), ('bfv_vector', <function bfv_vector at 0x7f04f92f0280>), ('bfv_vector_from', <function bfv_vector_from at 0x7f04f92f0310>), ('ckks_tensor', <function ckks_tensor at 0x7f04f92f05e0>), ('ckks_tensor_from', <function ckks_tensor_from at 0x7f04f92f0670>), ('ckks_vector', <function ckks_vector at 0x7f04f92f0430>), ('ckks_vector_from', <function ckks_vector_from at 0x7f04f92f04c0>), ('context', <function context at 0x7f04f92f0040>), ('context_from', <function context_from at 0x7f04f92f00d0>), ('enc_matmul_encoding', <function enc_matmul_encoding at 0x7f04f9344f70>), ('im2col_encoding', <function im2col_encoding at 0x7f0510582b80>), ('lazy_bfv_tensor_from', <function lazy_bfv_tensor_from at 0x7f04f92f08b0>), ('lazy_bfv_vector_from', <function lazy_bfv_vector_from at 0x7f04f92f03a0>), ('lazy_ckks_tensor_from', <function lazy_ckks_tensor_from at 0x7f04f92f0700>), ('lazy_ckks_vector_from', <function lazy_ckks_vector_from at 0x7f04f92f0550>), ('plain_tensor', <function plain_tensor at 0x7f04f92f0160>), ('plain_tensor_from', <function plain_tensor_from at 0x7f04f92f01f0>)]\n"
     ]
    }
   ],
   "source": [
    "from inspect import getmembers, isfunction\n",
    "\n",
    "import tenseal \n",
    "print(getmembers(tenseal, isfunction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import tenseal as ts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "context = ts.context(\n",
    "            ts.SCHEME_TYPE.CKKS,\n",
    "            poly_modulus_degree=32768,\n",
    "            coeff_mod_bit_sizes=[60, 40, 40, 60]\n",
    "          )\n",
    "\n",
    "context.generate_galois_keys()\n",
    "context.global_scale = 2**40\n",
    "\n",
    "def newton_method_div_init(a, number_iters = 73):\n",
    "    number = np.finfo(float).eps # number to get inverse of\n",
    "    for i in range(number_iters): # iteration number\n",
    "        number = number*(2-a*number) # update\n",
    "        #print(i,number)\n",
    "    return number\n",
    "\n",
    "def gold_div(a,b,iter = 1):\n",
    "    r = 1/b\n",
    "    #r = #newton_method_div_init(b,40)\n",
    "    #print(a,b)\n",
    "    for i in range(0,iter):\n",
    "        a = r*a\n",
    "        b = r*b\n",
    "        r = 2 + -1*b\n",
    "    return a \n",
    "\n",
    "def newton_method_sq(number, number_iters=2):\n",
    "    a = number # number to get square root of\n",
    "    for i in range(number_iters): # iteration number\n",
    "        number = 0.5 *(number+gold_div(a,number))\n",
    "        #number = 0.5 * (number+a/number)\n",
    "    #print(\"sqrt of:\",a,\"is =\", number)\n",
    "    return number\n",
    "\n",
    "def pow_summa(x):\n",
    "    sum = 0 \n",
    "    for i in range(0,len(x)):\n",
    "       sum = sum + x[i]*x[i]\n",
    "    #print(\"pow_sum of\",x,\"is =\",sum)\n",
    "    return sum\n",
    "\n",
    "def norm(v):\n",
    "    #print(\"pow_sum =\",pow_summa(v))\n",
    "    v_norm = newton_method_sq(pow_summa(v))\n",
    "    #print(\"norm of v is =\",v_norm)\n",
    "    return v_norm\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def gold_square(s, iterations = 10):\n",
    "    #y = np_invsqrt(s)\n",
    "    y = gold_div(1,newton_method_sq(s,10))\n",
    "    x = s*y\n",
    "    h = y*0.5\n",
    "    for i in range(0,iterations):\n",
    "        r = 0.5-x*h\n",
    "        x = x + x*r\n",
    "        h = h + h*r\n",
    "    return x, 2*h\n",
    "\n",
    "def pow_eig_comb(a,iterations = 5):\n",
    "    a_len = len(a)\n",
    "    Big_lamb = np.zeros(a_len)\n",
    "    Big_w = np.zeros((a_len,a_len)) #vector is the size of the initial matrix\n",
    "    for i in range(0,a_len):\n",
    "        #x = np.random.rand(a_len,1)     #random initial vector\n",
    "        x = np.ones((a_len,1)) \n",
    "        #print(x)\n",
    "        w = gold_div(x,np.linalg.norm(x))      #scaled random initial vector\n",
    "        #x/np.linalg.norm(x)          \n",
    "        for j in range(0,iterations):\n",
    "            x = np.dot(a,w)                #expensive would be nice if replaceable\n",
    "            lambda_new = np.linalg.norm(x) #can't do this on encrypted data but good enough for now (need goldschmidt)\n",
    "            w = gold_div(x,lambda_new)\n",
    "            #x / lambda_new             #need gold_div\n",
    "            if j+2 == iterations:\n",
    "                w_old = w[0]\n",
    "        #print(i,\"here\")\n",
    "        div = w[0]/w_old #gold_div(w[0],w_old)     #used to check if eigenvalue is negative \n",
    "        lambda_new = div*lambda_new     \n",
    "        w = div*w\n",
    "        Big_lamb[i] = lambda_new          #storing eigenval and vectors in their separate matrices\n",
    "        Big_w[i] = w.T\n",
    "        a = a+-1*lambda_new*w*w.T\n",
    "    return Big_lamb, Big_w\n",
    "\n",
    "def summa(x):\n",
    "    x_len = len(x)\n",
    "    sum = 0 \n",
    "    for i in range(0,x_len):\n",
    "        sum = sum + x[i]\n",
    "    return sum\n",
    "\n",
    "def dist_metric(p,q):\n",
    "    p = np.asarray(p).flatten()\n",
    "    q = np.asarray (q).flatten()\n",
    "    sum1 = np.sum((p+-1*q)*(p+-1*q))\n",
    "    #summa((p+-1*q)*(p+-1*q))\n",
    "    sq1 = newton_method_sq(sum1,2)\n",
    "    return sq1\n",
    "\n",
    "def predict (W, mu , projections, y, X):\n",
    "    minDist = float(\"inf\")\n",
    "    minClass = -1\n",
    "    Q = project (W, X.reshape (1 , -1) , mu)\n",
    "    for i in range (len(projections)):\n",
    "        dist = dist_metric( projections[i], Q)\n",
    "        if dist < minDist:\n",
    "            minDist = dist\n",
    "            minClass = i\n",
    "    return minClass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "v1 = np.array([0, 1, 2, 3, 4])\n",
    "#m1 = [[0,1,2,3,4],[0,1,2,3,4]]\n",
    "v2 = [4, 3, 2, 1, 0]\n",
    "sum_test = [1,1,1,1,1]\n",
    "#enc_tns1 = ts.ckks_tensor(context, v1)\n",
    "#enc_tns2 = ts.ckks_tensor(context, sum_test)\n",
    "#result = enc_tns1 * enc_tns2\n",
    "#print(\"Plain equivalent: {} * {}\\nDecrypted result: {}.\".format(v1, sum_test, result.decrypt()))\n",
    "#encrypted vectors\n",
    "\n",
    "def gold_div_vec(a,b,iter = 10): #divide vectors\n",
    "    sum = 0\n",
    "    for i in range(0,len(a)):\n",
    "        sum = sum + gold_div(a[i],b[i],iter)\n",
    "    return sum\n",
    "\n",
    "def vec_mult(v1,v2):\n",
    "    n = len(v1)\n",
    "    #print(\"v2_size =\",np.size(v2))\n",
    "    #print(n,len(v2))\n",
    "    v_mult = []\n",
    "    for i in range(0,n): \n",
    "        v_mult.append(v1[i]*v2[i])\n",
    "    return np.sum(v_mult)\n",
    "\n",
    "#function for encrypting every element in a vector as an encrypted vector:\n",
    "def enc_vec(v1):\n",
    "    enc_v1 = []\n",
    "    vv1 = []\n",
    "    for i in range(0,len(v1)):\n",
    "        vv1 = [v1[i]]\n",
    "        enc_v1.append(ts.ckks_vector(context,vv1))\n",
    "    return(np.array(enc_v1))\n",
    "\n",
    "#function for decrypting every element in a vector:\n",
    "def dec_vec(v1):\n",
    "    dec_v1 = []\n",
    "    vv1 = []\n",
    "    for i in range(0,len(v1)):\n",
    "        vv1 = v1[i].decrypt()               #decrypts a \"vector element\" which is just an element formed as a vector for encryption purposes\n",
    "        dec_v1.append(vv1[0])               \n",
    "    return(dec_v1)\n",
    "\n",
    "#print(np.size(v1))\n",
    "\n",
    "#def mean_vec(v1):\n",
    " #   sum = summa(v1)\n",
    " #   mean = sum* newton_method_div_init(len(v1),80)\n",
    " #   return mean\n",
    "\n",
    "\n",
    "enc_v1 = enc_vec(v1)\n",
    "enc_v2 = enc_vec(v2)\n",
    "#print(enc_v1)\n",
    "dec_v1 = dec_vec(enc_v1)\n",
    "#print(dec_v1)\n",
    "\n",
    "#print(\"sum_v1 =\",summa(enc_v1).decrypt())\n",
    "#mean_v1 = mean_vec(enc_v1)\n",
    "#print(mean_v1.decrypt())\n",
    "\n",
    "def enc_pictures(X2):\n",
    "    #making the encrypted pictures by first reverting them to a less dimension turning each picture into a 1D vector\n",
    "    enc_pics = []\n",
    "    for i in range(0,len(X2)):  \n",
    "        enc_pic = enc_vec(X2[i])                #encrypting the vectors using tenseal with built in function ckks_vector\n",
    "        enc_pics.append(enc_pic)                #We then store all the encrypted pictures in\n",
    "    return enc_pics\n",
    "\n",
    "def dec_pictures(X):\n",
    "    dec_pics = []\n",
    "    vv1 = []\n",
    "    for i in range(0,len(X)):\n",
    "        dec_pic = dec_vec(X[i])\n",
    "        dec_pics.append(dec_pic)\n",
    "    return(dec_pics)\n",
    "\n",
    "#mean_v1 = mean_vec(enc_v1)\n",
    "#print(mean_vec.decrypt())\n",
    "#enc_v1 = ts.ckks_vector(context, v1)\n",
    "#summ = ts.ckks_vector(context, sum_test)\n",
    "#a = enc_v1 * summ\n",
    "#print(a.decrypt())\n",
    "\n",
    "#summa(enc_v1,4)\n",
    "#enc_m1 = ts.ckks_vector(context, m1)\n",
    "#enc_v1 = ts.ckks_vector(context,v1)\n",
    "#enc_v2 = ts.ckks_vector(context, v2)\n",
    "#enc_sum = ts.ckks_vector(context, sum_test)\n",
    "#result = enc_v1.dot(enc_v2)\n",
    "\n",
    "#print(result.decrypt())\n",
    "#print(dist_metric(enc_v1,enc_v2))\n",
    "#print(enc_m1)\n",
    "#result = enc_v1 + enc_v2\n",
    "#print(result.decrypt())\n",
    "#result = dist_metric(enc_v1,enc_v2)\n",
    "#print(result)\n",
    "#print(result.decrypt()) # ~ [4, 4, 4, 4, 4]\n",
    "\n",
    "#result = enc_v1.dot(enc_v2)\n",
    "#result.decrypt()\n",
    "\n",
    "#encrypting all the elements of a vector \n",
    "#print(np.linalg.norm(v1))\n",
    "#vector_test = enc_v1\n",
    "\n",
    "#e = enc_v1[2]*enc_v2[2]\n",
    "\n",
    "#print(\"e =\",e.decrypt())\n",
    "\n",
    "def vec_dot(v1,v2):\n",
    "    n = len(v1)\n",
    "    m = len(v2)\n",
    "    #print(m,n)\n",
    "    v_mat = [[]]*m          #making an empty \"matrix\" of size m\n",
    "    #print(np.shape(v1))\n",
    "    #print(np.shape(v2))\n",
    "    for i in range(0,m):\n",
    "        v_mult = []         #initialize the inner matrix which need to be reinitialized each time because ckks vectors are an annoyance\n",
    "        for j in range(0,n): \n",
    "            v_mult.append(v1[i]*v2[j]) #appending is done here since that is the only acceptable thing for a ckks vector for some reason\n",
    "        v_mat[i] = v_mult   #putting the size n vector into the ith slot of the size m \"matrix\"\n",
    "    return v_mat\n",
    "\n",
    "\n",
    "q = vec_mult(enc_v1,enc_v2)\n",
    "#print(q.decrypt())\n",
    "w = np.dot(v1,v2)\n",
    "#print(w)\n",
    "#print(w)\n",
    "#print(q.decrypt())\n",
    "#print(enc_v1)\n",
    "#print(len(enc_v1),len(v2))\n",
    "\n",
    "e = vec_dot(enc_v1,enc_v2)\n",
    "dec_e = dec_pictures(e)\n",
    "#print(dec_e)\n",
    "#print(np.shape(dec_e))\n",
    "\n",
    "#summa = np.sum(enc_v1)\n",
    "#print(summa.decrypt())\n",
    "#enc_v1_2 = ts.ckks_vector(context,v1)\n",
    "#print(enc_v1_2.__sizeof__())\n",
    "#print(ts.ckks_vector.data())\n",
    "\n",
    "#print(enc_v1_2.load(context))\n",
    "\n",
    "#print(np.dot(enc_v1,enc_v2).decrypt())\n",
    "#print(v2)\n",
    "#print(np.argsort(- np.array(enc_v2)).decrypt())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tenseal.tensors.ckksvector.CKKSVector object at 0x7ff80b5427f0>\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'CKKSVector' object has no attribute '__getitem__'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_249/2780564182.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[0;31m#ts.ckks_vector(context,matrix)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menc_mat2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menc_mat2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menc_mat2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m \u001b[0;31m#print(matrix.reshape(1 , -1))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'CKKSVector' object has no attribute '__getitem__'"
     ]
    }
   ],
   "source": [
    "def matrix_mult(m1,m2):\n",
    "    r1 = len(m1)         #mxn \n",
    "    r2 = len(m2)      #nxk\n",
    "    c2 = len(m2[0])\n",
    "    mul2 = np.zeros((r1,c2))\n",
    "    for i in range(0,r1):\n",
    "        for j in range(0,c2):\n",
    "            for k in range(0,r2):\n",
    "                mul2[i][j] = mul2[i][j] + m1[i][k]*m2[k][j]\n",
    "    return mul2\n",
    "def matrix_mult(m1,m2):\n",
    "    r1 = len(m1)         #mxn \n",
    "    r2 = len(m2)      #nxk\n",
    "    c2 = len(m2[0])\n",
    "    #mul = [[]]*r1                    #r1xc2 = mxk\n",
    "    mul3 = []\n",
    "    #mul2 = np.zeros((r1,c2))\n",
    "    for i in range(0,r1):\n",
    "        m_mult = []\n",
    "        for j in range(0,c2):\n",
    "            m_mult2 = []\n",
    "            for k in range(0,r2):\n",
    "                #m1[0][0]*m2[0][0]\n",
    "                #print(m1[0][0].decrypt())\n",
    "                #mul2[i][j] = mul2[i][j] + m1[i][k]*m2[k][j]\n",
    "                m_mult2.append(m1[i][k]*m2[k][j])\n",
    "            #print(dec_vec(m_mult2))\n",
    "            m_mult.append(np.sum(m_mult2))\n",
    "        mul3.append(m_mult)\n",
    "        #mul[i] = m_mult\n",
    "        #print(mul2)\n",
    "    return mul3\n",
    "\n",
    "def transpose(matrix):\n",
    "    rows = len(matrix)\n",
    "    columns = len(matrix[0])\n",
    "\n",
    "    matrix_T = []\n",
    "    for j in range(columns):\n",
    "        row = []\n",
    "        for i in range(rows):\n",
    "           row.append(matrix[i][j])\n",
    "        matrix_T.append(row)\n",
    "\n",
    "    return matrix_T    \n",
    "\n",
    "matrix = np.array([\n",
    "  [73, 0.5, 8],\n",
    "  [81, -5, 66],\n",
    "  [-100, -78, -2],\n",
    "  [0, 9, 17],\n",
    "  [69, 11 , 10],\n",
    "])\n",
    "\n",
    "enc_mat = np.array(enc_pictures(matrix))\n",
    "#print(transpose(dec_pictures(enc_mat)))\n",
    "#print(matrix)\n",
    "qwert = np.dot(enc_mat.T,enc_mat)\n",
    "#print(dec_pictures(qwert))\n",
    "#print(np.dot(matrix.T,matrix))\n",
    "#print(dec_pictures(matrix_mult(transpose(enc_mat),enc_mat)))\n",
    "enc_mat2 = ts.ckks_vector(context,matrix[0])\n",
    "#ts.ckks_vector(context,matrix)\n",
    "print(enc_mat2)\n",
    "print(enc_mat2.__getattribute__(len(enc_mat2)-1))\n",
    "#print(matrix.reshape(1 , -1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Eigenfaces: Survey and Implementation from Scratch\n",
    "## Author: Svetlana Topalova"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Abstract\n",
    "Eigenfaces method is used for face recognition. The problem with the image representation we are given is its high dimensionality. The question is: Are all dimensions equally useful for us? We can only make a decision if there’s any variance in data, so what we are looking for are the components that account for most of the information. The Principal Component Analysis (PCA) turn a set of possibly correlated variables into a smaller set of uncorrelated variables. The idea is, that a high-dimensional dataset is often described by correlated variables and therefore only a few meaningful dimensions account for most of the information. The PCA method finds the directions with the greatest variance in the data, called principal components. In the recognition process, an eigenface is formed for the given face image, and the Euclidian distances between this eigenface and the previously stored eigenfaces are calculated. The eigenface with the smallest Euclidian distance is the one the person resembles the most."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Eigenfaces\n",
    "**Eigenfaces** is the name given to a set of **eigenvectors** when they are used in the computer vision problem of human face recognition. The approach of using eigenfaces for recognition was developed by Sirovich and Kirby (1987) and used by Matthew Turk and Alex Pentland in face classification. The eigenvectors are derived from the covariance matrix of the probability distribution over the high-dimensional vector space of face images. The eigenfaces themselves form a basis set of all images used to construct the covariance matrix. This produces dimension reduction by allowing the smaller set of basis images to represent the original training images. Classification can be achieved by comparing how faces are represented by the basis set.\n",
    "\n",
    "Eigenfaces refers to an appearance-based approach to face recognition that seeks to capture the variation in a collection of face images and use this information to encode and compare images of individual faces in a holistic (as opposed to a parts-based or feature-based) manner. Specifically, the eigenfaces are the principal components of a distribution of faces, or equivalently, the eigenvectors of the covariance matrix of the set of face images, where an image with N pixels is considered a point (or vector) in N-dimensional space. The idea of using principal components to represent human faces was developed by Sirovich and Kirby (Sirovich and Kirby 1987) and used by Turk and Pentland (Turk and Pentland 1991) for face detection and recognition. The Eigenface approach is considered by many to be the first working facial recognition technology, and it served as the basis for one of the top commercial face recognition technology products. Since its initial development and publication, there have been many extensions to the original method and many new developments in automatic face recognition systems. Eigenfaces is still often considered as a baseline comparison method to demonstrate the minimum expected performance of such a system.\n",
    "\n",
    "The motivation of Eigenfaces is twofold:\n",
    "\n",
    "* Extract the relevant facial information, which may or may not be directly related to human intuition of face features such as the eyes, nose, and lips. One way to do so is to capture the statistical variation between face images.\n",
    "* Represent face images efficiently. To reduce the computation and space complexity, each face image can be represented using a small number of parameters.\n",
    "\n",
    "The eigenfaces may be considered as a set of features which characterize the global variation among face images. Then each face image is approximated using a subset of the eigenfaces, those associated with the largest eigenvalues. These features account for the most variance in the training set.[1]\n",
    "\n",
    "A set of eigenfaces can be generated by performing a mathematical process called principal component analysis (PCA) on a large set of images depicting different human faces. Informally, eigenfaces can be considered a set of \"standardized face ingredients\", derived from statistical analysis of many pictures of faces. Any human face can be considered to be a combination of these standard faces. For example, one's face might be composed of the average face plus 10% from eigenface 1, 55% from eigenface 2, and even -3% from eigenface 3. Remarkably, it does not take many eigenfaces combined together to achieve a fair approximation of most faces. Also, because a person's face is not recorded by a digital photograph, but instead as just a list of values (one value for each eigenface in the database used), much less space is taken for each person's face.[2]\n",
    "### Eigenvalues and eigenvectors\n",
    "In linear algebra, an eigenvector or characteristic vector of a linear transformation is a non-zero vector that only changes by a scalar factor when that linear transformation is applied to it. More formally, if $ T $ is a linear transformation from a vector space V over a field F into itself and v is a vector in V that is not the zero vector, then v is an eigenvector of $ T $ if $ {T}(v) $ is a scalar multiple of $ v $. This condition can be written as the equation\n",
    "\n",
    "$$ {T}(v) = \\lambda v $$\n",
    "where $ \\lambda  $ is a scalar in the field $ F $, known as the eigenvalue, characteristic value, or characteristic root associated with the eigenvector $ v $.\n",
    "\n",
    "If the vector space $ V $ is finite-dimensional, then the linear transformation $ T $ can be represented as a square matrix $ A $, and the vector $ v $ by a column vector, rendering the above mapping as a matrix multiplication on the left hand side and a scaling of the column vector on the right hand side in the equation\n",
    "\n",
    "$$ Av = \\lambda v $$\n",
    "There is a correspondence between n by n square matrices and linear transformations from an n-dimensional vector space to itself. For this reason, it is equivalent to define eigenvalues and eigenvectors using either the language of matrices or the language of linear transformations.\n",
    "\n",
    "Eigenvalues and eigenvectors give rise to many closely related mathematical concepts:\n",
    "* The set of all eigenvectors of a linear transformation, each paired with its corresponding eigenvalue, is called the eigensystem of that transformation.\n",
    "* The set of all eigenvectors of T corresponding to the same eigenvalue, together with the zero vector, is called an eigenspace or characteristic space of T.\n",
    "* If the set of eigenvectors of T form a basis of the domain of T, then this basis is called an eigenbasis.[3]\n",
    "\n",
    "### PCA\n",
    "Principal component analysis (PCA) was invented in 1901 by Karl Pearson. PCA is a statistical procedure that uses an **orthogonal transformation** to convert a set of observations of possibly correlated variables into a **set of values of linearly uncorrelated variables called principal components**. If there are ${\\displaystyle n}$ n observations with ${\\displaystyle p}$ p variables, then the number of distinct principal components is ${\\displaystyle \\min(n-1,p)}$ . This transformation is defined in such a way that the **first principal component has the largest possible variance** (that is, accounts for as much of the variability in the data as possible), and each succeeding component in turn has the highest variance possible under the constraint that it is orthogonal to the preceding components. The resulting vectors are an uncorrelated orthogonal basis set. PCA is sensitive to the relative scaling of the original variables.\n",
    "\n",
    "PCA is mostly used as a tool in **exploratory data analysis and for making predictive models**. It's often used to visualize genetic distance and relatedness between populations. PCA can be done by eigenvalue decomposition of a data covariance (or correlation) matrix or singular value decomposition of a data matrix, usually after mean centering (and normalizing or using Z-scores) the data matrix for each attribute. The results of a PCA are usually discussed in terms of component scores, sometimes called factor scores (the transformed variable values corresponding to a particular data point), and loadings (the weight by which each standardized original variable should be multiplied to get the component score).\n",
    "\n",
    "PCA is **the simplest of the true eigenvector-based multivariate analyses**. Often, its operation can be thought of as **revealing the internal structure of the data in a way that best explains the variance** in the data. If a multivariate dataset is visualised as a set of coordinates in a high-dimensional data space (1 axis per variable), PCA can supply the user with a lower-dimensional picture, a projection of this object when viewed from its most informative viewpoint. This is done by **using only the first few principal components** so that the **dimensionality** of the transformed data is **reduced**.[4]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate EigenFaces\n",
    "The pictures constituting the training set should have been taken under the same lighting conditions, and must be normalized to have the eyes and mouths aligned across all images. They must also be all resampled to a common pixel resolution (r × c). \n",
    "The images in the given training set have resolution 250x250.\n",
    "#### 1. Read Images \n",
    "Obtaining face images ${\\displaystyle I_{1}, I_{2}, ..., I_{n}}$ (training faces)\n",
    "We read all images in the specified directory using the function **read_images**. \n",
    "Images are divided by subcategories which are the names of the persons. These names will keep in separate array as a reference between the image and the person's name. Used images are downloaded from [http://vis-www.cs.umass.edu/lfw/]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_DIR = 'training-images'\n",
    "DEFAULT_SIZE = [2, 2] \n",
    "\n",
    "def read_images(image_path=IMAGE_DIR, default_size=DEFAULT_SIZE):\n",
    "    images = []\n",
    "    images_names = []\n",
    "    image_dirs = [image for image in os.listdir(image_path) if not image.startswith('.')]\n",
    "    for image_dir in image_dirs:\n",
    "        dir_path = os.path.join(image_path, image_dir)\n",
    "        image_names = [image for image in os.listdir(dir_path) if not image.startswith('.')]\n",
    "        for image_name in image_names:\n",
    "            image = Image.open (os.path.join(dir_path, image_name))\n",
    "            image = image.convert (\"L\")\n",
    "            # resize to given size (if given )\n",
    "            if (default_size is not None ):\n",
    "                image = image.resize (default_size , Image.ANTIALIAS )\n",
    "            images.append(np.asarray (image , dtype =np. uint8 ))\n",
    "            images_names.append(image_dir)\n",
    "    return [images,images_names]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Assemble Data Matrix\n",
    "Represent every image $ {I_{i}} $ as a vector G, where G is an $1x(rc)$ vector, corresponding to an **r × c** face image  $ {I_{i}} $. \n",
    "\n",
    "<img src=\"image_vector.png\" />\n",
    "See [8]\n",
    "\n",
    "We use the function **as_row_matrix** to assemble the images into a data matrix. **Each row** of the data matrix is **one image**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def as_row_matrix (X):\n",
    "    if len (X) == 0:\n",
    "        return np. array ([])\n",
    "    mat = np. empty ((0 , np.size(X [0]) ), dtype =X [0]. dtype )\n",
    "    for row in X:\n",
    "        mat = np.vstack(( mat , np.asarray( row ).reshape(1 , -1))) # 1 x r*c \n",
    "    #enc_mat = ts.ckks_vector(context, mat)\n",
    "    return mat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Compute the mean face $\\mu$. \n",
    "\n",
    "The mean vector consists of the means of each variable and the variance-covariance matrix consists of the variances of the variables along the main diagonal and the covariances between each pair of variables in the other matrix positions.\n",
    "[9]\n",
    "\n",
    "The average of the image set is calculated as:\n",
    "<img src=\"mean_face_formula.png\" />\n",
    "See [7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def enc_pictures(X2):\n",
    "    #making the encrypted pictures by first reverting them to a less dimension turning each picture into a 1D vector\n",
    "    enc_pics = []\n",
    "    for i in range(0,len(X2)):  \n",
    "        enc_pic = enc_vec(X2[i])                #encrypting the vectors using tenseal with built in function ckks_vector\n",
    "        enc_pics.append(enc_pic)                #We then store all the encrypted pictures in\n",
    "    return enc_pics\n",
    "\n",
    "def dec_pictures(X):\n",
    "    dec_pics = []\n",
    "    for i in range(0,len(X)):\n",
    "        dec_pic = dec_vec(X[i])\n",
    "        dec_pics.append(dec_pic)\n",
    "    return(dec_pics)\n",
    "\n",
    "\n",
    "[X, y] = read_images()      #images, imgae_name\n",
    "X2 = as_row_matrix(X)\n",
    "\n",
    "enc_pics = enc_pictures(X2)\n",
    "\n",
    "average_weight_matrix = np.reshape(as_row_matrix(X).mean(axis=0), X[0].shape)\n",
    "plt.imshow(average_weight_matrix, cmap=plt.cm.gray)\n",
    "plt.title(\"Mean Face\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[110.98129083620489, 108.71713665609208, 116.37752496565554, 106.71713378708533]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def row_summa(x):\n",
    "    sum = np.zeros(len(x[0]))\n",
    "    for j in range(len(x)):#2500\n",
    "        sum = sum + x[j]\n",
    "    return sum\n",
    "\n",
    "def mean_vec(v1):\n",
    "    mean = [] \n",
    "    sum = np.sum(v1,axis=0) #row_summa(v1) # \n",
    "    div = gold_div(1,len(v1)) #\n",
    "    for i in range(len(v1[0])):\n",
    "        mean.append(sum[i]*div)\n",
    "    return mean\n",
    "\n",
    "mu = mean_vec(enc_pics)  #this is the equivalent of as_row_matrix(X).mean(axis=0)\n",
    "#print(dec_vec(np.sum(enc_pics,axis=0)))\n",
    "\n",
    "#print(X2.mean(axis=0))\n",
    "#print(X2)\n",
    "#print(mean_vec(X2))\n",
    "print(dec_vec(mu))\n",
    "average_weight_matrix2 = np.reshape(dec_vec(mu), X[0].shape)\n",
    "plt.imshow(average_weight_matrix2, cmap=plt.cm.gray)\n",
    "plt.title(\"Mean Face\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. Calculate PCA :\n",
    "We define function **pca** to calculate it in the following steps:\n",
    "##### Step 1. Subtract the mean. The average image a has to be subtracted from each original image in X.\n",
    "    \n",
    "##### Step 2. Calculate the eigenvectors and eigenvalues of the covariance matrix S. \n",
    "In probability theory and statistics, a covariance matrix (also known as dispersion matrix or variance–covariance matrix) is a matrix whose element in the i, j position is the covariance between the i-th and j-th elements of a random vector. A random vector is a random variable with multiple dimensions. Each element of the vector is a scalar random variable. Each element has either a finite number of observed empirical values or a finite or infinite number of potential values. The potential values are specified by a theoretical joint probability distribution.\n",
    "Compute the the Covariance Matrix S\n",
    "<img src=\"covariance _matrix.png\" />\n",
    "            See [7]\n",
    "\n",
    "Compute the eigenvalues $\\lambda_{i}$ and eigenvectors $v_{i}$ of S\n",
    "<img src=\"eigenvalues.png\" />\n",
    "            See [7]\n",
    "            \n",
    "Each eigenvector has the same dimensionality (number of components) as the original images, and thus can itself be seen as an image. The eigenvectors of this covariance matrix are therefore called eigenfaces. They are the directions in which the images differ from the mean image. Usually this will be a computationally expensive step (if at all possible), but the practical applicability of eigenfaces stems from the possibility to compute the eigenvectors of S efficiently, without ever computing S explicitly, as detailed below.\n",
    "\n",
    "##### Step 3. Choose the principal components. \n",
    "Sorting the eigenvalues with np.argsort in descending order and arrange eigenvectors accordingly. The number of principal components k is determined arbitrarily by setting a threshold ε on the total variance. Total variance ${\\displaystyle v=n\\cdot (\\lambda _{1}+\\lambda _{2}+...+\\lambda _{n})}$, n = number of data images by\n",
    "k is the smallest number satisfies : ${\\displaystyle {\\frac {n(\\lambda _{1}+\\lambda _{2}+...+\\lambda _{k})}{v}}>\\epsilon } $ \n",
    "We calculate it with function **get_number_of_components_to_preserve_variance** for variance=0.95.\n",
    "<img src=\"select_eigenfaces.png\" />\n",
    "See [6]\n",
    "\n",
    "The k principal components of the observed vector x are then given by:\n",
    "\n",
    "$y = W^{T} (x - \\mu)$\n",
    "\n",
    "where $W = (v_{1}, v_{2}, \\ldots, v_{k})$. \n",
    "\n",
    "See [7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "here\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "scale out of bounds",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_249/3348122677.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     89\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m \u001b[0meigenvalues\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0meigenvectors\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mmu\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 91\u001b[0;31m \u001b[0;34m[\u001b[0m\u001b[0meigenvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meigenvectors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmean\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpca\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menc_pics\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0meigenvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"eig =\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0meigenvalues\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#the as_row_matrix turns the pictures from being in a matrix format to a vectore format making them be instead of NxN to be N^2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_249/3348122677.py\u001b[0m in \u001b[0;36mpca\u001b[0;34m(X, y, num_components)\u001b[0m\n\u001b[1;32m     75\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"here\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m         \u001b[0;31m#np.dot(X.T,X)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 77\u001b[0;31m         \u001b[0mC\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmatrix_mult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     78\u001b[0m         \u001b[0;34m[\u001b[0m \u001b[0meigenvalues\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0meigenvectors\u001b[0m \u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpow_eig_comb\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mC\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_249/3348122677.py\u001b[0m in \u001b[0;36mmatrix_mult\u001b[0;34m(m1, m2)\u001b[0m\n\u001b[1;32m     42\u001b[0m             \u001b[0mm_mult2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mr2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m                 \u001b[0mm_mult2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mm1\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mm2\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m             \u001b[0mm_mult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mm_mult2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m         \u001b[0mmul3\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mm_mult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tenseal/tensors/abstract_tensor.py\u001b[0m in \u001b[0;36m__mul__\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m    114\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__mul__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;34m\"AbstractTensor\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 116\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    117\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__imul__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;34m\"AbstractTensor\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tenseal/tensors/ckksvector.py\u001b[0m in \u001b[0;36mmul\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m     96\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;34m\"CKKSVector\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m         \u001b[0mother\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_operand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mother\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"float\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 98\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     99\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_wrap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: scale out of bounds"
     ]
    }
   ],
   "source": [
    "#def vec_dot(v1,v2):\n",
    "#    #print(np.matmul(v1,v2))\n",
    "#    n = len(v1)\n",
    "#    m = len(v2)\n",
    "#    print(np.shape(v1))\n",
    "#    v_mat = [[]]*m          #making an empty \"matrix\" of size m\n",
    "#    for i in range(0,m): \n",
    "#        v_mult = []         #initialize the inner matrix which need to be reinitialized each time because ckks vectors are an annoyance\n",
    "#        for j in range(0,n):\n",
    "#            #v_mult.append(v1[i]*v2[j]) \n",
    "#            v_mult.append(v1[i][j]*v2[j][i]) #appending is done here since that is the only acceptable thing for a ckks vector for some reason\n",
    "#        v_mat[i] = v_mult   #putting the size n vector into the ith slot of the size m \"matrix\"\n",
    "#    #print(v_mat)\n",
    "#    return v_mat\n",
    "\n",
    "def get_number_of_components_to_preserve_variance(eigenvalues, variance=.95):\n",
    "    for ii, eigen_value_cumsum in enumerate(np.cumsum(eigenvalues) / np.sum(eigenvalues)):\n",
    "        if eigen_value_cumsum > variance:\n",
    "            return ii\n",
    "\n",
    "def transpose(matrix):\n",
    "    rows = len(matrix)\n",
    "    columns = len(matrix[0])\n",
    "\n",
    "    matrix_T = []\n",
    "    for j in range(columns):\n",
    "        row = []\n",
    "        for i in range(rows):\n",
    "           row.append(matrix[i][j])\n",
    "        matrix_T.append(row)\n",
    "\n",
    "    return matrix_T\n",
    "\n",
    "def matrix_mult(m1,m2):\n",
    "    r1 = len(m1)         #mxn \n",
    "    r2 = len(m2)      #nxk\n",
    "    c2 = len(m2[0])\n",
    "    mul3 = []\n",
    "    for i in range(0,r1):\n",
    "        m_mult = []\n",
    "        for j in range(0,c2):\n",
    "            m_mult2 = []\n",
    "            for k in range(0,r2):\n",
    "                m_mult2.append(m1[i][k]*m2[k][j])\n",
    "            m_mult.append(np.sum(m_mult2))\n",
    "        mul3.append(m_mult)\n",
    "    return mul3\n",
    "\n",
    "def pca (X, y, num_components =0):\n",
    "    [n,d] = np.shape(X)\n",
    "    if ( num_components <= 0) or ( num_components >n):\n",
    "        num_components = n\n",
    "        X = np.array(X)\n",
    "        #print(dec_pictures(X))\n",
    "        #print(np.mean(dec_pictures(X),axis=0))\n",
    "        mu = mean_vec(X)\n",
    "        #print(dec_vec(mu))\n",
    "        for i in range(len(mu)):\n",
    "            mu[i] = mu[i]*-1\n",
    "        #mu = mu*-1\n",
    "        #print(dec_vec(mu))\n",
    "        #Q = matrix_mult(transpose(X),X)\n",
    "        #Q2 = np.dot(transpose(X),X)\n",
    "        #print(len(Q),len(Q[0]))\n",
    "        #print(dec_pictures(Q))\n",
    "        #print(dec_pictures(Q2))\n",
    "        #for i in range(len(X)):\n",
    "        #    for j in range(len(X[0])):\n",
    "        #        X[i][j] = X[i][j] + mu[j]\n",
    "        X = np.add(X,mu)    #<-- it goes from list to array which messes everything up\n",
    "        #print(dec_pictures(X))\n",
    "        #print(len(X),len(X[0]))\n",
    "    if n>d:\n",
    "        # Covariance Matrix\n",
    "        print(\"here\")\n",
    "        #np.dot(X.T,X)\n",
    "        C = matrix_mult(X.T,X)\n",
    "        [ eigenvalues , eigenvectors ] = pow_eig_comb(C)\n",
    "    else:\n",
    "        # Covariance Matrix\n",
    "        C = matrix_mult(X,X.T)\n",
    "        [ eigenvalues , eigenvectors ] = pow_eig_comb(C)\n",
    "        eigenvectors = np.dot(X.T, eigenvectors )\n",
    "        for i in range (n):\n",
    "            eigenvectors [:,i] = eigenvectors [:,i]/ np.linalg.norm( eigenvectors [:,i])\n",
    "    num_components = get_number_of_components_to_preserve_variance(eigenvalues)\n",
    "    eigenvalues = eigenvalues [0: num_components ].copy ()\n",
    "    eigenvectors = eigenvectors [: ,0: num_components ].copy ()\n",
    "    return [ eigenvalues , eigenvectors , mu]  \n",
    "\n",
    "[eigenvalues, eigenvectors, mean] = pca(enc_pics, y)\n",
    "print(np.shape(eigenvalues))\n",
    "print(\"eig =\",eigenvalues) #the as_row_matrix turns the pictures from being in a matrix format to a vectore format making them be instead of NxN to be N^2 \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def matrix_mult(m1,m2):\n",
    "    r1 = len(m1)         #mxn \n",
    "    r2 = len(m2)      #nxk\n",
    "    c2 = len(m2[0])\n",
    "    mul2 = np.zeros((r1,c2))\n",
    "    for i in range(0,r1):\n",
    "        for j in range(0,c2):\n",
    "            for k in range(0,r2):\n",
    "                mul2[i][j] = mul2[i][j] + m1[i][k]*m2[k][j]\n",
    "    return mul2\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#print(X2.T)\n",
    "#print(\"transpose = \",transpose(X2))\n",
    "def pca (X, y, num_components =0):\n",
    "    [n,d] = np.shape(X)\n",
    "    num_components = n\n",
    "    mu = mean_vec(X)\n",
    "    for i in range(len(mu)):\n",
    "        mu[i] = -1*mu[i]\n",
    "    X = np.add(X,mu)\n",
    "    if n>d:\n",
    "        C = matrix_mult(X.T,X)\n",
    "        [ eigenvalues , eigenvectors ] = pow_eig_comb(C)\n",
    "    else:\n",
    "        C = matrix_mult(X,X.T)\n",
    "        [ eigenvalues , eigenvectors ] = pow_eig_comb(C)\n",
    "        eigenvectors = np.dot(X.T, eigenvectors )\n",
    "        for i in range (n):\n",
    "            eigenvectors [:,i] = eigenvectors [:,i]/ np.linalg.norm( eigenvectors [:,i])\n",
    "    num_components = get_number_of_components_to_preserve_variance(eigenvalues)\n",
    "    eigenvalues = eigenvalues [0: num_components ].copy ()\n",
    "    eigenvectors = eigenvectors [: ,0: num_components ].copy ()\n",
    "    return [ eigenvalues , eigenvectors , mu]  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Eigenfaces with the highest eigenvalues are calculated using the training set. They are called the ghost faces.\n",
    "Those are shown in the figure below. For some databases, the ghost faces turn out to be sharper. For some others, they are\n",
    "blurred, like the ones in this case. The sharpness depends on the backgrounds and the other details of the images.\n",
    "Here the images are very detailed and the background, the facial expressions, and the lighting conditions are quite\n",
    "varying. Thus the sharpness is sacrificed. [10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 720x720 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def subplot ( title , images , rows , cols , sptitle =\"\", sptitles =[] , colormap = plt.cm.gray, filename = None, figsize = (10, 10) ):\n",
    "    fig = plt.figure(figsize = figsize)\n",
    "    # main title\n",
    "    fig.text (.5 , .95 , title , horizontalalignment =\"center\")\n",
    "    for i in range ( len ( images )):\n",
    "        ax0 = fig.add_subplot( rows , cols ,( i +1))\n",
    "        plt.setp ( ax0.get_xticklabels() , visible = False )\n",
    "        plt.setp ( ax0.get_yticklabels() , visible = False )\n",
    "        if len ( sptitles ) == len ( images ):\n",
    "            plt.title(\"%s #%s\" % ( sptitle , str ( sptitles [i ]) )  )\n",
    "        else:\n",
    "            plt.title(\"%s #%d\" % ( sptitle , (i +1) )  )\n",
    "        plt.imshow(np.asarray(images[i]) , cmap = colormap )\n",
    "    if filename is None :\n",
    "        plt.show()\n",
    "    else:\n",
    "        fig.savefig( filename )\n",
    "\n",
    "        \n",
    "E = []\n",
    "number = eigenvectors.shape[1]\n",
    "for i in range (min(number, 16)):\n",
    "    e = eigenvectors[:,i].reshape(X[0].shape )\n",
    "    E.append(np.asarray(e))\n",
    "# plot them and store the plot to \" python_eigenfaces .pdf\"\n",
    "subplot ( title =\"Eigenfaces\", images=E, rows =4, cols =4, colormap =plt.cm.gray , filename =\"python_pca_eigenfaces.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cumulative sum of first highest eigenvalues is given below. Based on the plot it's clear we should pick these features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def get_eigen_value_distribution(eigenvectors):\n",
    "    return np.cumsum(eigenvectors) / np.sum(eigenvectors)\n",
    "\n",
    "def plot_eigen_value_distribution(eigenvectors, interval):\n",
    "    plt.scatter(interval, get_eigen_value_distribution(eigenvectors)[interval])\n",
    "\n",
    "plot_eigen_value_distribution(eigenvalues, range(0, number))\n",
    "plt.title(\"Cumulative sum of the first {0} eigenvalues\".format(number))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Representing faces onto this basis\n",
    "\n",
    "Each face can be represented as a linear combination of the eigenfaces. **Each face can also be estimated using the\n",
    "\"best\" eigenfaces, which have the largest eigenvalues and represent the largest variations in the face image database.**[10]\n",
    "\n",
    "The reconstruction from the PCA basis is given by:\n",
    "\n",
    "$x = W y + \\mu$\n",
    "\n",
    "where $W = (v_{1}, v_{2}, \\ldots, v_{k})$.\n",
    "\n",
    "See [7]\n",
    "\n",
    "Each face (minus the mean) $ {I_{i}} $ in the training set can be represented as a linear combination of the best K eigenvectors:\n",
    "<img src=\"representation.png\" />\n",
    "\n",
    "See [8]\n",
    "\n",
    "Now we **reconstruct** the first image from smaller training set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 720x720 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def project (W , X , mu):\n",
    "    return np.dot (X - mu , W) #(X-mu).dot(W)\n",
    "def reconstruct (W , Y , mu) :\n",
    "    return np.dot (Y , W.T) + mu\n",
    "\n",
    "[X_small, y_small] = read_images(image_path=\"training-images-small\") \n",
    "[eigenvalues_small, eigenvectors_small, mean_small] = pca(as_row_matrix(X_small), y_small)\n",
    "\n",
    "steps =[i for i in range (eigenvectors_small.shape[1])]\n",
    "E = []\n",
    "for i in range (len(steps)):\n",
    "    numEvs = steps[i]\n",
    "    P = project(eigenvectors_small[: ,0: numEvs ], X_small[0].reshape (1 , -1) , mean_small)\n",
    "    R = reconstruct(eigenvectors_small[: ,0: numEvs ], P, mean_small)\n",
    "    # reshape and append to plots\n",
    "    R = R.reshape(X_small[0].shape )\n",
    "    E.append(np.asarray(R))\n",
    "subplot ( title =\"Reconstruction\", images =E, rows =4, cols =4, \n",
    "         sptitle =\"Eigenvectors \", sptitles =steps , colormap =plt.cm.gray , filename =\"python_pca_reconstruction.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Face Recognition using Eigenfaces\n",
    "\n",
    "Now we use the algorithm for face detection **in an unknown image**\n",
    "In the recognition process, an eigenface is formed for the given face image, and the Euclidian distances between this eigenface and the previously stored eigenfaces are calculated. The eigenface with the smallest Euclidian distance is the one the person resembles the most.\n",
    "\n",
    "The Eigenfaces method then performs face recognition by:\n",
    "    1. Projecting all training samples into the PCA subspace.\n",
    "    2. Projecting the query image into the PCA subspace.\n",
    "\n",
    "Given input image vector ${\\displaystyle u\\in \\Re ^{n}}$, project the image onto the eigenspace:\n",
    "\n",
    "$y = W u + \\mu$\n",
    "\n",
    "where $W = (v_{1}, v_{2}, \\ldots, v_{k})$.\n",
    "\n",
    "    3. Finding the nearest neighbor between the projected training images and the projected queryimage.\n",
    "\n",
    "Comment: we use the common Euclidean distance to compute the distance, however, it has been reported that other algorithms perform better.\n",
    "\n",
    "The **Euclidean distance** between points p and q is the length of the line segment connecting them.\n",
    "\n",
    "${\\displaystyle {\\begin{aligned}d(\\mathbf {p} ,\\mathbf {q} ) ={\\sqrt {(q_{1}-p_{1})^{2}+(q_{2}-p_{2})^{2}+\\cdots +(q_{n}-p_{n})^{2}}}\\\\[8pt]&={\\sqrt {\\sum _{i=1}^{n}(q_{i}-p_{i})^{2}}}.\\end{aligned}}} $ \n",
    "\n",
    "See[11]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "[[-1405.68017014 -2169.83872204  -791.90606594]]\n",
      "3\n",
      "[[-3435.45737379  7093.40466764  2136.95287947]]\n",
      "3\n",
      "[[-1909.83282309  8217.04733711  3497.91376254]]\n",
      "3\n",
      "[[-5424.61008322  4292.04039339  -404.33665353]]\n",
      "3\n",
      "[[-2950.19046865  1530.1510451   1148.2298523 ]]\n",
      "3\n",
      "[[ 1177.69272903 -3417.52055504  -252.671446  ]]\n",
      "3\n",
      "[[-1033.21441053  2879.26189722  1497.29883436]]\n",
      "3\n",
      "[[-2840.39357478  1611.05812672 -2709.56945057]]\n",
      "3\n",
      "[[-5594.39394583  6500.07350735    66.9553247 ]]\n",
      "3\n",
      "[[ 1759.43080314 -1788.03325751 -2021.68215255]]\n",
      "3\n",
      "[[ 4806.60001073 -2797.94262132  1395.63000968]]\n",
      "3\n",
      "[[-2542.50809594 -1816.02290316 -1313.96424351]]\n",
      "3\n",
      "[[ 382.188043   -681.26206133 -528.79973356]]\n",
      "3\n",
      "[[ 3127.80558831 -9180.0225152   -426.22302709]]\n",
      "3\n",
      "[[ -940.05661947 -3485.49655752 -2317.28704804]]\n",
      "3\n",
      "[[-4430.92239041  2650.19166275 -1737.46274104]]\n",
      "3\n",
      "[[  920.16165902 -4721.05679796  -258.16739908]]\n",
      "3\n",
      "[[ -555.89071388 -3365.86486693 -2159.90604379]]\n",
      "3\n",
      "[[ 5753.77639452 -7009.30385904   457.27311523]]\n",
      "3\n",
      "[[  4704.88067985 -10968.03151134    908.5582476 ]]\n",
      "3\n",
      "[[ 2956.54560926 -4766.45104178   519.81187728]]\n",
      "3\n",
      "[[-1844.78884306  -993.69995555 -1277.16706556]]\n",
      "3\n",
      "[[ 2434.20539118 -1917.21713461  2145.0205986 ]]\n",
      "3\n",
      "[[-1947.13052169  2201.18514843  -429.55908659]]\n",
      "3\n",
      "[[4059.86750254  648.03647404 1120.72465084]]\n",
      "3\n",
      "[[ 5116.97280149 -4696.66811356  -219.76113797]]\n",
      "3\n",
      "[[4844.71392954 1491.16653167 3045.88049428]]\n",
      "3\n",
      "[[ -529.82595404 -2934.2730332  -3254.62365746]]\n",
      "3\n",
      "[[-2761.87531401  5082.48964646   538.67868106]]\n",
      "3\n",
      "[[-5073.89767693  7652.65134431  -219.12250978]]\n",
      "3\n",
      "[[-5358.68261133 10358.65947374   740.37164387]]\n",
      "3\n",
      "[[ 2762.80697113 -2238.27910051     8.80177342]]\n",
      "3\n",
      "[[-678.45246544  -73.39950948 -395.50136308]]\n",
      "3\n",
      "[[ -420.3754155   2009.67437984 -1417.76324598]]\n",
      "3\n",
      "[[1306.90281157 2489.24119835 1234.73598176]]\n",
      "3\n",
      "[[-1342.78229066  5338.5178038    128.53798611]]\n",
      "3\n",
      "[[ 1096.53648264 -3482.26684804 -1839.84555212]]\n",
      "3\n",
      "[[1819.23102375 -149.45528354  474.05569159]]\n",
      "3\n",
      "[[-2188.44685914  5191.68117094   -90.46929698]]\n",
      "3\n",
      "[[-1648.48493416  1158.26186888  -157.12517783]]\n",
      "3\n",
      "[[  158.16566244 -1117.28082914    36.71686665]]\n",
      "3\n",
      "[[-3833.36023165  3519.37984027   907.52015034]]\n",
      "3\n",
      "[[1629.18311859 -582.7940742  1434.1984268 ]]\n",
      "3\n",
      "[[-3518.67646862  3910.70162865   218.37900641]]\n",
      "3\n",
      "[[ 1516.97326483 -2108.3996907   2084.20369526]]\n",
      "3\n",
      "[[-1011.21459137  4020.18771882  2029.58652762]]\n",
      "3\n",
      "[[ 4138.27444709 -1062.47274998  1279.82565855]]\n",
      "3\n",
      "[[ -441.28619729  2336.79689032 -1196.91424472]]\n",
      "3\n",
      "[[ 2050.37050486 -4019.29978995   916.73416624]]\n",
      "3\n",
      "[[-4185.95352699  8868.28404896  -214.21721433]]\n",
      "3\n",
      "[[ -404.09580179 -1312.68460751 -1839.52807192]]\n",
      "3\n",
      "[[ 6135.18004729 -9393.8410111  -1481.22876277]]\n",
      "3\n",
      "[[ 5594.01489756 -8801.26480353 -1017.79351077]]\n",
      "['Audrey_Sauret', 'Augustin_Calleri', 'Augustin_Calleri', 'Augustin_Calleri', 'Asmaa_Assad', 'Assad_Ahmadi', 'Astrid_Eyzaguirre', 'Azmi_Bishara', 'Aaron_Eckhart', 'Asa_Hutchinson', 'Asa_Hutchinson', 'Aung_San_Suu_Kyi', 'Aung_San_Suu_Kyi', 'Adam_Sandler', 'Adam_Sandler', 'Adam_Sandler', 'Adam_Sandler', 'Adam_Sandler', 'Adam_Sandler', 'Adam_Sandler', 'Adam_Sandler', 'Adam_Sandler', 'Art_Lopez', 'Arthur_Johnson', 'Atiabet_Ijan_Amabel', 'Augusto_Roa_Bastos', 'Augusto_Roa_Bastos', 'Ashton_Kutcher', 'Ashton_Kutcher', 'Ashton_Kutcher', 'Atsushi_Sato', 'Ashraf_Alasmar', 'Audrey_Lacroix', 'Ashraf_Ghani', 'Atom_Egoyan', 'Astrid_Betancourt', 'Ataollah_Mohajerani', 'Art_Howe', 'Art_Howe', 'Art_Howe', 'Art_Howe', 'Asif_Ali_Zardari', 'Askar_Akayev', 'Arthur_Martinez', 'Artieas_Shanks', 'Austin_Kearns', 'Art_Cooper', 'Ashanti', 'Ashanti', 'Ashanti', 'Astou_Ndiaye-Diatta', 'Asif_Hanif', 'Ascencion_Barajas']\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 360x360 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def dist_metric(p,q,):\n",
    "    p = np.asarray(p).flatten()\n",
    "    q = np.asarray (q).flatten()\n",
    "    #sum0 = np.sum (np. power ((p-q) ,2))\n",
    "    sum1 = summa((p+-1*q)*(p+-1*q))\n",
    "    print(p.size)\n",
    "    #sq2 = np.sqrt(sum1)\n",
    "    #sq0, _ = gold_square(sum1,30)\n",
    "    sq1 = newton_method_sq(sum1,30)\n",
    "    #print(\"start\")\n",
    "    #print(sq0)\n",
    "    #print(sq1)\n",
    "    #print(sq2)\n",
    "    #print(\"stop\")\n",
    "    #np.sqrt (np.sum (np. power ((p-q) ,2)))\n",
    "    return sq1\n",
    "\n",
    "def predict (W, mu , projections, y, X):\n",
    "    minDist = float(\"inf\")\n",
    "    minClass = -1\n",
    "    Q = project (W, X.reshape (1 , -1) , mu)\n",
    "    for i in range (len(projections)):\n",
    "        dist = dist_metric( projections[i], Q)\n",
    "        print(projections[i])\n",
    "        if dist < minDist: #we send dist to client to decrypt it and find the minmum distance\n",
    "                            #shuffle indexes and distances\n",
    "            minDist = dist\n",
    "            minClass = i\n",
    "    #print(dist)\n",
    "    return minClass\n",
    "\n",
    "projections = []\n",
    "for xi in X:\n",
    "    projections.append(project (eigenvectors, xi.reshape(1 , -1) , mean))\n",
    "\n",
    "image = Image.open(\"test.jpg\")\n",
    "image = image.convert (\"L\")\n",
    "if (DEFAULT_SIZE is not None ):\n",
    "    image = image.resize (DEFAULT_SIZE , Image.ANTIALIAS )\n",
    "test_image = np. asarray (image , dtype =np. uint8 )\n",
    "predicted = predict(eigenvectors, mean , projections, y, test_image)\n",
    "print(y)\n",
    "\n",
    "subplot ( title =\"Prediction\", images =[test_image, X[predicted]], rows =1, cols =2, \n",
    "         sptitles = [\"Unknown image\", \"Prediction :{0}\".format(y[predicted])] , colormap =plt.cm.gray , \n",
    "         filename =\"prediction_test.png\", figsize = (5,5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion\n",
    "\n",
    "The Eigenfaces method was applied on small training set of images. The most significant eigenfaces, which have the largest eigenvalues and represent the largest variations in the face image database, were found and shown. Reconstruction of an image was done by representing it as a linear combination of the eigenfaces.\n",
    "\n",
    "Although the unknown image was successfully predicted by the algorithm, failure probability is relatively high because of the small number of training images. The future work will focus on increasing success rate for larger databases and combining with other face recognition algorithms."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### References\n",
    "\n",
    "[1] [http://www.scholarpedia.org/article/Eigenfaces]\n",
    "\n",
    "[2] [https://en.wikipedia.org/wiki/Eigenface]\n",
    "\n",
    "[3] [https://en.wikipedia.org/wiki/Eigenvalues_and_eigenvectors]\n",
    "\n",
    "[4] [https://en.wikipedia.org/wiki/Principal_component_analysis]\n",
    "\n",
    "[5] [https://github.com/bugra/EigenFace]\n",
    "\n",
    "[6] [https://www.youtube.com/watch?v=n3sDhHH5tFg]\n",
    "\n",
    "[7] [https://docs.opencv.org/2.4/modules/contrib/doc/facerec/facerec_tutorial.html]\n",
    "\n",
    "[8] [http://www.vision.jhu.edu/teaching/vision08/Handouts/case_study_pca1.pdf]\n",
    "\n",
    "[9] [https://www.itl.nist.gov/div898/handbook/pmc/section5/pmc541.htm]\n",
    "\n",
    "[10] [https://ac.els-cdn.com/S2212017312000242/1-s2.0-S2212017312000242-main.pdf]\n",
    "\n",
    "[11] [https://en.wikipedia.org/wiki/Euclidean_distance]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
